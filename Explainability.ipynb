{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries, Datesets, Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from src.preprocessing_functions import create_generator\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import eli5\n",
    "from eli5.tensorflow import explain_weights_tf, explain_prediction_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths in a dict for train, test, valid folders with wildfire and nowildfire images \n",
    "\n",
    "images_path = '/Users/silvanoquarto/Desktop/PROJECTS/Data_Wildfire_Project'\n",
    "splits = ['train', 'test', 'valid']\n",
    "labels = ['wildfire', 'nowildfire']\n",
    "\n",
    "image_paths = {f\"{split}_{label}\": [] for split in splits for label in labels}\n",
    "\n",
    "for split in splits:\n",
    "    for label in labels:\n",
    "        path = os.path.join(images_path, split, label)\n",
    "        if os.path.exists(path):  \n",
    "            image_files = os.listdir(path)\n",
    "            full_paths = [os.path.join(path, img) for img in image_files]\n",
    "            image_paths[f\"{split}_{label}\"].extend(full_paths)\n",
    "            print(f\"- {split.capitalize()} set for {label} uploaded correctly!!\")\n",
    "        else:\n",
    "            print(f\"Warning: {path} does not exist :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augumentation and normalization\n",
    " \n",
    "print('Data augumentation and normalization for training...')\n",
    "train_generator = create_generator(images_path, 'train')\n",
    "\n",
    "print('Data augumentation and normalization for validation...')\n",
    "validation_generator = create_generator(images_path, 'valid')\n",
    "\n",
    "print('Data augumentation and normalization for test...')\n",
    "test_generator = create_generator(images_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "model = load_model('Saved_Models/wildfire_detection_transfer_learning.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELI5 Explainability using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain weights\n",
    "\n",
    "explain_weights_tf(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain predictions on a sample image\n",
    "\n",
    "sample_image = next(train_generator)[0][0]\n",
    "explain_prediction_tf(model, sample_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
